{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 質問をスコア化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 09:20:52.149157: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-12 09:20:52.149172: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import numpy as np\n",
    "import onnx\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202412120920"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDIT ME!\n",
    "now = datetime.datetime.now()\n",
    "CURRENT_ID = int(now.strftime(\"%Y%m%d%H%M\"))\n",
    "# CURRENT_ID = 202412092216\n",
    "CURRENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_ROOT = \"../../\"\n",
    "DIR_DATA = os.path.join(DIR_ROOT, \"data\")   \n",
    "DIR_QUESTIONS = os.path.join(DIR_DATA, \"questions\")\n",
    "DIR_SAVED_MODELS = os.path.join(DIR_DATA, \"saved_models\")\n",
    "\n",
    "QUESTION_ID = 202405311421\n",
    "\n",
    "# DATA CONFIG\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# MODEL CONFIG\n",
    "MAX_EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "ALPHA = 10.0 # Non-Question Loss(0~0.05)\n",
    "BETA = 1.0 # Ranking Loss\n",
    "MARGIN = 0.5\n",
    "DIM_USE = 512\n",
    "HIDDEN_DIMS = [DIM_USE, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_model_url=\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/multilingual/2\",\n",
    "        use_dim=DIM_USE, \n",
    "        hidden_dims=HIDDEN_DIMS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        alpha=ALPHA,\n",
    "        beta=BETA,\n",
    "        margin=MARGIN\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Universal Sentence Encoder\n",
    "        with tf.device(\"/CPU:0\"):\n",
    "            self.use = hub.load(use_model_url)\n",
    "        \n",
    "        # MLP layers\n",
    "        layers = []\n",
    "        input_dim = use_dim \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.Dropout(0.2)\n",
    "            ])\n",
    "            input_dim = hidden_dim\n",
    "        \n",
    "        # 最終出力層\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "    def encode_text(self, texts):\n",
    "        # USEでテキストをエンコード\n",
    "        embeddings = self.use(texts)\n",
    "        return torch.tensor(embeddings.numpy(), device=self.device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: バッチのテキスト\n",
    "        embeddings = self.encode_text(x)\n",
    "        scores = self.mlp(embeddings).squeeze(-1)\n",
    "        return scores\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        texts, levels = batch\n",
    "        scores = self(texts)\n",
    "        loss = self.compute_loss(scores, levels, stage='train')\n",
    "        \n",
    "        self.log('train/loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        texts, levels = batch\n",
    "        scores = self(texts)\n",
    "        loss = self.compute_loss(scores, levels, stage='val')   \n",
    "        \n",
    "        self.log('val/loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def compute_loss(self, y_pred, y_true, stage):\n",
    "        # 基本的なMSE損失\n",
    "        base_loss = F.mse_loss(y_pred, y_true.float())\n",
    "        \n",
    "        # 非疑問文に対するヒンジ損失\n",
    "        is_non_question = (y_true <= 0).float()\n",
    "        non_question_loss = torch.mean(\n",
    "            is_non_question * torch.maximum(\n",
    "                torch.tensor(0.0, device=self.device),\n",
    "                y_pred + self.hparams.margin\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 順序関係を保持するためのランキング損失\n",
    "        level_diff = y_true.unsqueeze(1) - y_true.unsqueeze(0)\n",
    "        pred_diff = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)\n",
    "        \n",
    "        ranking_loss = torch.mean(\n",
    "            torch.maximum(\n",
    "                torch.tensor(0.0, device=self.device),\n",
    "                -pred_diff * torch.sign(level_diff) + \n",
    "                self.hparams.margin * torch.abs(level_diff)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 最終的な損失は各項の重み付き和\n",
    "        total_loss = (\n",
    "            base_loss +\n",
    "            self.hparams.alpha * non_question_loss +\n",
    "            self.hparams.beta * ranking_loss\n",
    "        )\n",
    "        \n",
    "        # 各損失項もログに記録\n",
    "        self.log(f'{stage}/base_loss', base_loss)\n",
    "        self.log(f'{stage}/non_question_loss', non_question_loss)\n",
    "        self.log(f'{stage}/ranking_loss', ranking_loss)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            verbose=True\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val/loss\"\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, levels):\n",
    "        self.texts = texts\n",
    "        self.levels = levels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.levels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_texts,\n",
    "        train_levels,\n",
    "        val_texts,\n",
    "        val_levels,\n",
    "        batch_size=32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_texts = train_texts\n",
    "        self.train_levels = train_levels\n",
    "        self.val_texts = val_texts\n",
    "        self.val_levels = val_levels\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = QuestionDataset(\n",
    "            self.train_texts,\n",
    "            self.train_levels\n",
    "        )\n",
    "        self.val_dataset = QuestionDataset(\n",
    "            self.val_texts,\n",
    "            self.val_levels\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR_QUESTIONS, f\"{QUESTION_ID}.json\")) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = [] \n",
    "labels = []\n",
    "\n",
    "for questions_of_theme in data.values():\n",
    "    for level_id, questions_of_level in enumerate(questions_of_theme.values()):\n",
    "        for question in questions_of_level:\n",
    "            texts.append(question)\n",
    "            labels.append(int(level_id))\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, \n",
    "    labels, \n",
    "    train_size=TRAIN_RATIO,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データモジュールの準備\n",
    "data_module = QuestionDataModule(\n",
    "    train_texts,\n",
    "    train_labels,\n",
    "    val_texts,\n",
    "    val_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# モデルの初期化\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"architecture\": \"USE_MLP\",\n",
    "    \"hidden_dims\": HIDDEN_DIMS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"alpha\": ALPHA,\n",
    "    \"beta\": BETA,\n",
    "    \"margin\": MARGIN,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"project_id\": CURRENT_ID,\n",
    "    \"question_id\": QUESTION_ID\n",
    "}\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"gyuwan-question-level-prediction\",\n",
    "    config=config,\n",
    "    log_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(\n",
    "            monitor='val/loss',\n",
    "            patience=10,\n",
    "            mode='min'\n",
    "        ),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            monitor='val/loss',\n",
    "            dirpath=os.path.join(DIR_SAVED_MODELS, \"question_score\", f\"{CURRENT_ID}\"),\n",
    "            filename='question-scorer-{epoch:02d}-{val_loss:.2f}',\n",
    "            save_top_k=3,\n",
    "            mode='min'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 学習の実行\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(os.path.join(DIR_SAVED_MODELS, \"question_score\", f\"{CURRENT_ID}\", \"final.ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = 202412111510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 09:21:13.231211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-12 09:21:13.231346: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-12 09:21:13.231376: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-12 09:21:13.231397: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-12 09:21:13.231417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-12 09:21:13.231865: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-12 09:21:13.231891: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-12-12 09:21:13.231895: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-12-12 09:21:13.232085: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model.load_from_checkpoint(os.path.join(DIR_SAVED_MODELS, \"question_score\", f\"{MODEL_ID}\", \"final.ckpt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8537466717383035"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "for i in range(0, len(val_texts), BATCH_SIZE):\n",
    "    batch_texts = val_texts[i:i+BATCH_SIZE]\n",
    "    with torch.no_grad():\n",
    "        scores = model(batch_texts)\n",
    "    predictions.extend(scores.cpu().numpy())\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"text\": val_texts,\n",
    "    \"label\": val_labels,\n",
    "    \"prediction\": predictions\n",
    "})\n",
    "\n",
    "# +- 1の範囲で正解とする\n",
    "df[\"is_correct\"] = (df[\"label\"] - 1 <= df[\"prediction\"]) & (df[\"prediction\"] <= df[\"label\"] + 1)\n",
    "\n",
    "# 正解率\n",
    "accuracy = df[\"is_correct\"].mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index 以外の値を表示\n",
    "# ランダムに10件を表示\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_questions = [\n",
    "    \"顔認譍技術を使って、写真に写る人物の情報を自動的に解析する方法は考えられますか?\",\n",
    "    \"どうやったら燃費が良くなるように運転できますか?\",\n",
    "    \"今のどういう意味か分かった人いる？\",\n",
    "    \"これってどういう意味？\",\n",
    "    \"なるほど？\",\n",
    "    \"なるほど\",\n",
    "    \"よくわからん\",\n",
    "    \"納豆ネバネバ\",\n",
    "    \"これは面白いですね!\",\n",
    "    \"何が起きているのかわかりません。\",\n",
    "    \"もっと詳しく説明してください。\",\n",
    "    \"えっ、本当ですか?\",\n",
    "    \"私もやってみたいです!\",\n",
    "    \"私にはこの意味がわかりません。\",\n",
    "    \"なるほど、なるほど。\",\n",
    "    \"いつからこんなことが始まっていたんですか?\",\n",
    "    \"もっと情報が欲しいです。\",\n",
    "    \"驚いた! とても興味深いです。\"\n",
    "]\n",
    "sample_scores = model(sample_questions)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"text\": sample_questions,\n",
    "    \"prediction\": sample_scores.detach().numpy()\n",
    "}).sort_values(\"prediction\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3522772/413468199.py:39: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  return torch.tensor(embeddings.numpy(), device=self.device)\n"
     ]
    }
   ],
   "source": [
    "# ONNX形式で保存\n",
    "onnx_path = os.path.join(DIR_SAVED_MODELS, \"question_score\", f\"{MODEL_ID}\", \"model.onnx\")\n",
    "dummy_input = (\"What is the meaning of life?\",)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    input_names=[\"text\"],\n",
    "    output_names=[\"score\"],\n",
    "    dynamic_axes={\n",
    "        \"text\": {0: \"batch\"},\n",
    "        \"score\": {0: \"batch\"}\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gyuwan_question_scoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
