{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 質問をスコア化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 15:10:42.356096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-11 15:10:42.356110: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202412111510"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDIT ME!\n",
    "now = datetime.datetime.now()\n",
    "CURRENT_ID = int(now.strftime(\"%Y%m%d%H%M\"))\n",
    "# CURRENT_ID = 202412092216\n",
    "CURRENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_ROOT = \"../../\"\n",
    "DIR_DATA = os.path.join(DIR_ROOT, \"data\")   \n",
    "DIR_QUESTIONS = os.path.join(DIR_DATA, \"questions\")\n",
    "DIR_SAVED_MODELS = os.path.join(DIR_DATA, \"saved_models\")\n",
    "\n",
    "QUESTION_ID = 202405311421\n",
    "\n",
    "# DATA CONFIG\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# MODEL CONFIG\n",
    "MAX_EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "ALPHA = 10.0 # Non-Question Loss(0~0.05)\n",
    "BETA = 1.0 # Ranking Loss\n",
    "MARGIN = 0.5\n",
    "DIM_USE = 512\n",
    "HIDDEN_DIMS = [DIM_USE, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_model_url=\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/multilingual/2\",\n",
    "        use_dim=DIM_USE, \n",
    "        hidden_dims=HIDDEN_DIMS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        alpha=ALPHA,\n",
    "        beta=BETA,\n",
    "        margin=MARGIN\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Universal Sentence Encoder\n",
    "        with tf.device(\"/CPU:0\"):\n",
    "            self.use = hub.load(use_model_url)\n",
    "        \n",
    "        # MLP layers\n",
    "        layers = []\n",
    "        input_dim = use_dim \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.Dropout(0.2)\n",
    "            ])\n",
    "            input_dim = hidden_dim\n",
    "        \n",
    "        # 最終出力層\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "    def encode_text(self, texts):\n",
    "        # USEでテキストをエンコード\n",
    "        embeddings = self.use(texts)\n",
    "        return torch.tensor(embeddings.numpy(), device=self.device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: バッチのテキスト\n",
    "        embeddings = self.encode_text(x)\n",
    "        scores = self.mlp(embeddings).squeeze(-1)\n",
    "        return scores\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        texts, levels = batch\n",
    "        scores = self(texts)\n",
    "        loss = self.compute_loss(scores, levels, stage='train')\n",
    "        \n",
    "        self.log('train/loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        texts, levels = batch\n",
    "        scores = self(texts)\n",
    "        loss = self.compute_loss(scores, levels, stage='val')   \n",
    "        \n",
    "        self.log('val/loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def compute_loss(self, y_pred, y_true, stage):\n",
    "        # 基本的なMSE損失\n",
    "        base_loss = F.mse_loss(y_pred, y_true.float())\n",
    "        \n",
    "        # 非疑問文に対するヒンジ損失\n",
    "        is_non_question = (y_true <= 0).float()\n",
    "        non_question_loss = torch.mean(\n",
    "            is_non_question * torch.maximum(\n",
    "                torch.tensor(0.0, device=self.device),\n",
    "                y_pred + self.hparams.margin\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 順序関係を保持するためのランキング損失\n",
    "        level_diff = y_true.unsqueeze(1) - y_true.unsqueeze(0)\n",
    "        pred_diff = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)\n",
    "        \n",
    "        ranking_loss = torch.mean(\n",
    "            torch.maximum(\n",
    "                torch.tensor(0.0, device=self.device),\n",
    "                -pred_diff * torch.sign(level_diff) + \n",
    "                self.hparams.margin * torch.abs(level_diff)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 最終的な損失は各項の重み付き和\n",
    "        total_loss = (\n",
    "            base_loss +\n",
    "            self.hparams.alpha * non_question_loss +\n",
    "            self.hparams.beta * ranking_loss\n",
    "        )\n",
    "        \n",
    "        # 各損失項もログに記録\n",
    "        self.log(f'{stage}/base_loss', base_loss)\n",
    "        self.log(f'{stage}/non_question_loss', non_question_loss)\n",
    "        self.log(f'{stage}/ranking_loss', ranking_loss)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            verbose=True\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val/loss\"\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, levels):\n",
    "        self.texts = texts\n",
    "        self.levels = levels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.levels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_texts,\n",
    "        train_levels,\n",
    "        val_texts,\n",
    "        val_levels,\n",
    "        batch_size=32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_texts = train_texts\n",
    "        self.train_levels = train_levels\n",
    "        self.val_texts = val_texts\n",
    "        self.val_levels = val_levels\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = QuestionDataset(\n",
    "            self.train_texts,\n",
    "            self.train_levels\n",
    "        )\n",
    "        self.val_dataset = QuestionDataset(\n",
    "            self.val_texts,\n",
    "            self.val_levels\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR_QUESTIONS, f\"{QUESTION_ID}.json\")) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = [] \n",
    "labels = []\n",
    "\n",
    "for questions_of_theme in data.values():\n",
    "    for level_id, questions_of_level in enumerate(questions_of_theme.values()):\n",
    "        for question in questions_of_level:\n",
    "            texts.append(question)\n",
    "            labels.append(int(level_id))\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, \n",
    "    labels, \n",
    "    train_size=TRAIN_RATIO,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 15:10:43.516927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-11 15:10:43.517130: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-11 15:10:43.517181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-11 15:10:43.517221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-11 15:10:43.517259: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-11 15:10:43.517943: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-11 15:10:43.517987: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-12-11 15:10:43.517994: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-12-11 15:10:43.518518: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# データモジュールの準備\n",
    "data_module = QuestionDataModule(\n",
    "    train_texts,\n",
    "    train_labels,\n",
    "    val_texts,\n",
    "    val_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# モデルの初期化\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"architecture\": \"USE_MLP\",\n",
    "    \"hidden_dims\": HIDDEN_DIMS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"alpha\": ALPHA,\n",
    "    \"beta\": BETA,\n",
    "    \"margin\": MARGIN,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"project_id\": CURRENT_ID,\n",
    "    \"question_id\": QUESTION_ID\n",
    "}\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"gyuwan-question-level-prediction\",\n",
    "    config=config,\n",
    "    log_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzacker\u001b[0m (\u001b[33mzacker-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241211_151045-ld7j3pet</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zacker-team/gyuwan-question-level-prediction/runs/ld7j3pet' target=\"_blank\">eager-sponge-10</a></strong> to <a href='https://wandb.ai/zacker-team/gyuwan-question-level-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zacker-team/gyuwan-question-level-prediction' target=\"_blank\">https://wandb.ai/zacker-team/gyuwan-question-level-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zacker-team/gyuwan-question-level-prediction/runs/ld7j3pet' target=\"_blank\">https://wandb.ai/zacker-team/gyuwan-question-level-prediction/runs/ld7j3pet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/gyuwan_question_scoring/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name | Type       | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | mlp  | Sequential | 395 K  | train\n",
      "--------------------------------------------\n",
      "395 K     Trainable params\n",
      "0         Non-trainable params\n",
      "395 K     Total params\n",
      "1.583     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e84010f9a904bcca28b83d92d2bde8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c638664a3664eb9ae1b12dcf788fcf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93985e701f4c46b0a490e686340364e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f9efdc9df94f5bbc59d3e10c5e7eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b11d295961842a591d09913a481f895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633f56b810e048eb967cc2228376f068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20daccfa5692402db43ca2cfe2234d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ed69709ac940878c507d824dd30b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8eef5d9147f47f490765c4772917c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba69e4e27214f35aa0ff2a89e42dff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596f64d984ab421ca5b8634617b6b848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575e9d8b6eea4d2794de589ffe8e2570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afac4a11624f476bb8e977e8c22b64b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7a4ed8c1af4a71b6ffda7d305f8c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb1e66d5dee4bd282b248c4ba74cfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f67e79c403641938323edbef51fa552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f7de2f4bf143fa8e2266dca67a4bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96505bf9200a43148715107cbed6cbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cc031f2b794fe5bca12b2042d3889c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729996586a9043b9a4363ad4a62a550d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbfbbaf5cf84c67a6f4106b316604a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a39d5b0fde4e5aa8d41e7eb05215f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa5405402ad4239bc273f364aa532ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66f5b5838554bcaa49c6f5888fa1235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c339bf42e24643c6ae29490be5a46365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035ab21c2ecc47e1a77fd2222d7d5dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a6aef4597b495b9a38f8cdf33152e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196c202928ba40479fb351bbbf51339e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e257805cbea74fff94a61cb148444219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf0b44a7fe24a6ba7e10c45c2a5ed67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402b2a1faaaf4fe1892f8b5ead5235bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903469aa5a9a4023899ef7f85526fef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(\n",
    "            monitor='val/loss',\n",
    "            patience=10,\n",
    "            mode='min'\n",
    "        ),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            monitor='val/loss',\n",
    "            dirpath=os.path.join(DIR_SAVED_MODELS, \"question_score\", f\"{CURRENT_ID}\"),\n",
    "            filename='question-scorer-{epoch:02d}-{val_loss:.2f}',\n",
    "            save_top_k=3,\n",
    "            mode='min'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 学習の実行\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(os.path.join(DIR_SAVED_MODELS, \"question_score\", f\"{CURRENT_ID}\", \"final.ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model.load_from_checkpoint(os.path.join(DIR_SAVED_MODELS, \"question_score\", f\"{CURRENT_ID}\", \"final.ckpt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8537466717383035"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "for i in range(0, len(val_texts), BATCH_SIZE):\n",
    "    batch_texts = val_texts[i:i+BATCH_SIZE]\n",
    "    with torch.no_grad():\n",
    "        scores = model(batch_texts)\n",
    "    predictions.extend(scores.cpu().numpy())\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"text\": val_texts,\n",
    "    \"label\": val_labels,\n",
    "    \"prediction\": predictions\n",
    "})\n",
    "\n",
    "# +- 1の範囲で正解とする\n",
    "df[\"is_correct\"] = (df[\"label\"] - 1 <= df[\"prediction\"]) & (df[\"prediction\"] <= df[\"label\"] + 1)\n",
    "\n",
    "# 正解率\n",
    "accuracy = df[\"is_correct\"].mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>What criteria should be considered when select...</td>\n",
       "      <td>7</td>\n",
       "      <td>6.720615</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>車を運転するとき、どうやって燃費を良くしますか？</td>\n",
       "      <td>4</td>\n",
       "      <td>3.335679</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280</th>\n",
       "      <td>建築士試験を受ける者にとって、建築という表現手法が持つ意味とは何でしょうか？</td>\n",
       "      <td>8</td>\n",
       "      <td>7.274127</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>イラストが可愛らしい</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.815837</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7468</th>\n",
       "      <td>この単語、複雑でしょう？</td>\n",
       "      <td>1</td>\n",
       "      <td>2.026802</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  prediction  \\\n",
       "442   What criteria should be considered when select...      7    6.720615   \n",
       "6707                           車を運転するとき、どうやって燃費を良くしますか？      4    3.335679   \n",
       "6280             建築士試験を受ける者にとって、建築という表現手法が持つ意味とは何でしょうか？      8    7.274127   \n",
       "2013                                         イラストが可愛らしい      0   -0.815837   \n",
       "7468                                       この単語、複雑でしょう？      1    2.026802   \n",
       "\n",
       "      is_correct  \n",
       "442         True  \n",
       "6707        True  \n",
       "6280        True  \n",
       "2013        True  \n",
       "7468       False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 以外の値を表示\n",
    "# ランダムに10件を表示\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>なるほど？</td>\n",
       "      <td>2.181482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>今のどういう意味か分かった人いる？</td>\n",
       "      <td>2.146297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>これってどういう意味？</td>\n",
       "      <td>1.998684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>納豆ネバネバ</td>\n",
       "      <td>-0.243632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>よくわからん</td>\n",
       "      <td>-0.755690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>なるほど</td>\n",
       "      <td>-0.918920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text  prediction\n",
       "2              なるほど？    2.181482\n",
       "0  今のどういう意味か分かった人いる？    2.146297\n",
       "1        これってどういう意味？    1.998684\n",
       "5             納豆ネバネバ   -0.243632\n",
       "4             よくわからん   -0.755690\n",
       "3               なるほど   -0.918920"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_questions = [\n",
    "    \"今のどういう意味か分かった人いる？\",\n",
    "    \"これってどういう意味？\",\n",
    "    \"なるほど？\",\n",
    "    \"なるほど\",\n",
    "    \"よくわからん\",\n",
    "    \"納豆ネバネバ\"\n",
    "]\n",
    "sample_scores = model(sample_questions)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"text\": sample_questions,\n",
    "    \"prediction\": sample_scores.detach().numpy()\n",
    "}).sort_values(\"prediction\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gyuwan_question_scoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
