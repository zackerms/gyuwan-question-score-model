{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 質問をスコア化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 22:16:54.411509: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-09 22:16:54.411524: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202412092216"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDIT ME!\n",
    "now = datetime.datetime.now()\n",
    "CURRENT_ID = int(now.strftime(\"%Y%m%d%H%M\"))\n",
    "CURRENT_ID = 202412092216\n",
    "CURRENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_ROOT = \"../../\"\n",
    "DIR_DATA = os.path.join(DIR_ROOT, \"data\")   \n",
    "DIR_QUESTIONS = os.path.join(DIR_DATA, \"questions\")\n",
    "DIR_SAVED_MODELS = os.path.join(DIR_DATA, \"saved_models\")\n",
    "\n",
    "QUESTION_ID = 202405311421\n",
    "\n",
    "# DATA CONFIG\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# MODEL CONFIG\n",
    "MAX_EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "ALPHA = 1.0\n",
    "BETA = 1.0\n",
    "MARGIN = 0.5\n",
    "DIM_USE = 512\n",
    "HIDDEN_DIMS = [DIM_USE, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_model_url=\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/multilingual/2\",\n",
    "        use_dim=DIM_USE, \n",
    "        hidden_dims=HIDDEN_DIMS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        alpha=ALPHA,\n",
    "        beta=BETA,\n",
    "        margin=MARGIN\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Universal Sentence Encoder\n",
    "        with tf.device(\"/CPU:0\"):\n",
    "            self.use = hub.load(use_model_url)\n",
    "        \n",
    "        # MLP layers\n",
    "        layers = []\n",
    "        input_dim = use_dim \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.Dropout(0.2)\n",
    "            ])\n",
    "            input_dim = hidden_dim\n",
    "        \n",
    "        # 最終出力層\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "    def encode_text(self, texts):\n",
    "        # USEでテキストをエンコード\n",
    "        embeddings = self.use(texts)\n",
    "        return torch.tensor(embeddings.numpy(), device=self.device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: バッチのテキスト\n",
    "        embeddings = self.encode_text(x)\n",
    "        scores = self.mlp(embeddings).squeeze(-1)\n",
    "        return scores\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        texts, levels = batch\n",
    "        scores = self(texts)\n",
    "        loss = self.compute_loss(scores, levels, stage='train')\n",
    "        \n",
    "        self.log('train/loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        texts, levels = batch\n",
    "        scores = self(texts)\n",
    "        loss = self.compute_loss(scores, levels, stage='val')   \n",
    "        \n",
    "        self.log('val/loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def compute_loss(self, y_pred, y_true, stage):\n",
    "        # 基本的なMSE損失\n",
    "        base_loss = F.mse_loss(y_pred, y_true.float())\n",
    "        \n",
    "        # 非疑問文に対するヒンジ損失\n",
    "        is_non_question = (y_true <= 0).float()\n",
    "        non_question_loss = torch.mean(\n",
    "            is_non_question * torch.maximum(\n",
    "                torch.tensor(0.0, device=self.device),\n",
    "                y_pred + self.hparams.margin\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 順序関係を保持するためのランキング損失\n",
    "        level_diff = y_true.unsqueeze(1) - y_true.unsqueeze(0)\n",
    "        pred_diff = y_pred.unsqueeze(1) - y_pred.unsqueeze(0)\n",
    "        \n",
    "        ranking_loss = torch.mean(\n",
    "            torch.maximum(\n",
    "                torch.tensor(0.0, device=self.device),\n",
    "                -pred_diff * torch.sign(level_diff) + \n",
    "                self.hparams.margin * torch.abs(level_diff)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 最終的な損失は各項の重み付き和\n",
    "        total_loss = (\n",
    "            base_loss +\n",
    "            self.hparams.alpha * non_question_loss +\n",
    "            self.hparams.beta * ranking_loss\n",
    "        )\n",
    "        \n",
    "        # 各損失項もログに記録\n",
    "        self.log(f'{stage}/base_loss', base_loss)\n",
    "        self.log(f'{stage}/non_question_loss', non_question_loss)\n",
    "        self.log(f'{stage}/ranking_loss', ranking_loss)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            verbose=True\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val/loss\"\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, levels):\n",
    "        self.texts = texts\n",
    "        self.levels = levels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.levels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_texts,\n",
    "        train_levels,\n",
    "        val_texts,\n",
    "        val_levels,\n",
    "        batch_size=32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_texts = train_texts\n",
    "        self.train_levels = train_levels\n",
    "        self.val_texts = val_texts\n",
    "        self.val_levels = val_levels\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = QuestionDataset(\n",
    "            self.train_texts,\n",
    "            self.train_levels\n",
    "        )\n",
    "        self.val_dataset = QuestionDataset(\n",
    "            self.val_texts,\n",
    "            self.val_levels\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR_QUESTIONS, f\"{QUESTION_ID}.json\")) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "texts = [] \n",
    "labels = []\n",
    "\n",
    "for questions_of_theme in data.values():\n",
    "    for level_id, questions_of_level in enumerate(questions_of_theme.values()):\n",
    "        for question in questions_of_level:\n",
    "            texts.append(question)\n",
    "            labels.append(int(level_id))\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, \n",
    "    labels, \n",
    "    train_size=TRAIN_RATIO,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 22:16:55.622406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-09 22:16:55.622603: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-09 22:16:55.622651: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-09 22:16:55.622688: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-09 22:16:55.622723: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-09 22:16:55.623401: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-09 22:16:55.623442: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-12-09 22:16:55.623448: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-12-09 22:16:55.624015: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# データモジュールの準備\n",
    "data_module = QuestionDataModule(\n",
    "    train_texts,\n",
    "    train_labels,\n",
    "    val_texts,\n",
    "    val_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# モデルの初期化\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"architecture\": \"USE_MLP\",\n",
    "    \"hidden_dims\": HIDDEN_DIMS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"alpha\": ALPHA,\n",
    "    \"beta\": BETA,\n",
    "    \"margin\": MARGIN,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "}\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"gyuwan-question-level-prediction\",\n",
    "    config=config,\n",
    "    log_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzacker\u001b[0m (\u001b[33mzacker-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241209_221657-wfaxnfif</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zacker-team/gyuwan-question-level-prediction/runs/wfaxnfif' target=\"_blank\">curious-sun-7</a></strong> to <a href='https://wandb.ai/zacker-team/gyuwan-question-level-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zacker-team/gyuwan-question-level-prediction' target=\"_blank\">https://wandb.ai/zacker-team/gyuwan-question-level-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zacker-team/gyuwan-question-level-prediction/runs/wfaxnfif' target=\"_blank\">https://wandb.ai/zacker-team/gyuwan-question-level-prediction/runs/wfaxnfif</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/gyuwan_question_scoring/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/zacker/dev/hackason/gyuwan_question_score/data/saved_models/question_score/202405311421 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/zacker/.pyenv/versions/anaconda3-2023.07-2/envs/gyuwan_question_scoring/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name | Type       | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | mlp  | Sequential | 395 K  | train\n",
      "--------------------------------------------\n",
      "395 K     Trainable params\n",
      "0         Non-trainable params\n",
      "395 K     Total params\n",
      "1.583     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4ff0b907404cc38b4ac88f08b2186d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a48fba93a8f45eb9bc3dac88de11675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b0f865ab09469bb29e340d4dd6a60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3bd331de70454491043e06e084a609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3393e791dcb4756973e5943bfa8f012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c2aac1d6b84387b6e8368b8634a820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbad324f56984ba287ff3b2e3aa8a5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1498520baae44884b9f5b2e0bf0cbd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb47e1102cf74e978bcdb546e0af27b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3b6ac7ba024e9f9845f02a3421f2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd863309a83463f918fa84f6eea375b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63deb45f5f99401cbf2497aebfb79ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129d77250540426dbf225fbad931c98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871f7c51dfd4487ebf7c9a4b6284c21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88112c28ab5e41d5b37d8a6efc5c3a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c9e41bc0c24f76afa024c098089141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cce08ebc318407a89be5baa9fd161ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddff66c76a5842cf97e4f8af4ae85b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29babbb9601c46e1a798a2c37075cc4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933d9f79036d4adbb865edfd3783250f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f82d904a401414eac462b7c651e11d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f033e9a261c47e7a477ceffaabedea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6cc3cd95df448ba63718bb2de9dc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3e4235aa8a4ed98a8ae3474ae75d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9541619ebfb44785a36747e8c012aa26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1eb3e5b565f411795189da161219580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863557db5f6041a09c221a5182220afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51984cdabd924e49b3abc8662757c7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d002764b74b74aa6b11e2e6590dd7997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c9cd3eb22148c0bc29046fe0978ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72931f0008c543c19dad6fee6102c198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d734b47b0304e0d8759b6a478c99467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(\n",
    "            monitor='val/loss',\n",
    "            patience=10,\n",
    "            mode='min'\n",
    "        ),\n",
    "        pl.callbacks.ModelCheckpoint(\n",
    "            monitor='val/loss',\n",
    "            dirpath=os.path.join(DIR_SAVED_MODELS, \"question_score\", f\"{QUESTION_ID}\"),\n",
    "            filename='question-scorer-{epoch:02d}-{val_loss:.2f}',\n",
    "            save_top_k=3,\n",
    "            mode='min'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 学習の実行\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(os.path.join(DIR_SAVED_MODELS, \"question_score\", f\"{QUESTION_ID}\", \"final.ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "for i in range(0, len(val_texts), BATCH_SIZE):\n",
    "    batch_texts = val_texts[i:i+BATCH_SIZE]\n",
    "    with torch.no_grad():\n",
    "        scores = model(batch_texts)\n",
    "    predictions.extend(scores.cpu().numpy())\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"text\": val_texts,\n",
    "    \"label\": val_labels,\n",
    "    \"prediction\": predictions\n",
    "})\n",
    "\n",
    "df[\"is_correct\"] = (df[\"label\"] == np.round(df[\"prediction\"])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7331</th>\n",
       "      <td>会議の議事録は残されますか？</td>\n",
       "      <td>3</td>\n",
       "      <td>3.034462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>この時系列データのトレンドはどのように変化していますか？</td>\n",
       "      <td>3</td>\n",
       "      <td>4.767453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10060</th>\n",
       "      <td>どうして雇用の多様化や働き方の自由度が高まる中で、社会保険労務士の専門性は重要性を増すのですか？</td>\n",
       "      <td>5</td>\n",
       "      <td>4.831195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>これってよく使われるフレーズ？</td>\n",
       "      <td>2</td>\n",
       "      <td>2.131057</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>このクエリの実行計画は効率的？</td>\n",
       "      <td>2</td>\n",
       "      <td>2.556882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  prediction  \\\n",
       "7331                                     会議の議事録は残されますか？      3    3.034462   \n",
       "5416                       この時系列データのトレンドはどのように変化していますか？      3    4.767453   \n",
       "10060  どうして雇用の多様化や働き方の自由度が高まる中で、社会保険労務士の専門性は重要性を増すのですか？      5    4.831195   \n",
       "329                                     これってよく使われるフレーズ？      2    2.131057   \n",
       "1863                                    このクエリの実行計画は効率的？      2    2.556882   \n",
       "\n",
       "       is_correct  \n",
       "7331            1  \n",
       "5416            0  \n",
       "10060           1  \n",
       "329             1  \n",
       "1863            0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 以外の値を表示\n",
    "# ランダムに10件を表示\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4728], device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([\"ざわざわ\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gyuwan_question_scoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
